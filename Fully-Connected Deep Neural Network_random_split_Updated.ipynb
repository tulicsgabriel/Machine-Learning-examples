{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected Deep Neural Network with random split validation\n",
    "\n",
    "### My updated template for a binary classification, with a confusion matrix\n",
    "\n",
    "### Metrics given:\n",
    "\n",
    "Accuracy, Matthews Correlation Coefficient\n",
    "\n",
    "For each class: Recall, Precision, F1 score, Specificity, Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import regularizers, losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.impute import SimpleImputer as Imputer #class\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import keras_metrics\n",
    "from keras import optimizers\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # https://jovianlin.io/feature-scaling/\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Csoport</th>\n",
       "      <th>Nem</th>\n",
       "      <th>SPI.raw_0_0</th>\n",
       "      <th>MFCC.mean_0_0_[E]_1</th>\n",
       "      <th>MFCC.std_0_0_[E]_1</th>\n",
       "      <th>MFCC.range_0_0_[E]_1</th>\n",
       "      <th>HNR.mean_5_5_[E]</th>\n",
       "      <th>HNR.std_5_5_[E]</th>\n",
       "      <th>HNR.range_5_5_[E]</th>\n",
       "      <th>...</th>\n",
       "      <th>IMF_ENTROPY_RATIO.range_0_0_[E-e:-i-2-y]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.mean_0_0_[O-A:-o-u]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.std_0_0_[O-A:-o-u]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.range_0_0_[O-A:-o-u]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.mean_0_0_[v-z-Z]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.std_0_0_[v-z-Z]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.range_0_0_[v-z-Z]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.mean_0_0_[b-d-g-dz-dZ-d']</th>\n",
       "      <th>IMF_ENTROPY_RATIO.std_0_0_[b-d-g-dz-dZ-d']</th>\n",
       "      <th>IMF_ENTROPY_RATIO.range_0_0_[b-d-g-dz-dZ-d']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA_002no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>0.702423</td>\n",
       "      <td>226.727241</td>\n",
       "      <td>15.565275</td>\n",
       "      <td>138.304191</td>\n",
       "      <td>7.702671</td>\n",
       "      <td>1.873980</td>\n",
       "      <td>8.800351</td>\n",
       "      <td>...</td>\n",
       "      <td>2.379776</td>\n",
       "      <td>1.229107</td>\n",
       "      <td>0.297684</td>\n",
       "      <td>1.656664</td>\n",
       "      <td>1.342090</td>\n",
       "      <td>0.599020</td>\n",
       "      <td>2.269212</td>\n",
       "      <td>2.035604</td>\n",
       "      <td>0.885508</td>\n",
       "      <td>3.693024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA_003no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>0.368337</td>\n",
       "      <td>188.198555</td>\n",
       "      <td>20.797340</td>\n",
       "      <td>127.246116</td>\n",
       "      <td>-3.235416</td>\n",
       "      <td>1.841550</td>\n",
       "      <td>6.213561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950906</td>\n",
       "      <td>1.054856</td>\n",
       "      <td>0.154813</td>\n",
       "      <td>0.754372</td>\n",
       "      <td>1.022489</td>\n",
       "      <td>0.159252</td>\n",
       "      <td>0.522101</td>\n",
       "      <td>1.098897</td>\n",
       "      <td>0.111197</td>\n",
       "      <td>0.488349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PA_004no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>0.810142</td>\n",
       "      <td>245.252498</td>\n",
       "      <td>13.106253</td>\n",
       "      <td>94.247744</td>\n",
       "      <td>9.765168</td>\n",
       "      <td>1.553110</td>\n",
       "      <td>7.726234</td>\n",
       "      <td>...</td>\n",
       "      <td>2.337904</td>\n",
       "      <td>1.175937</td>\n",
       "      <td>0.285692</td>\n",
       "      <td>1.626280</td>\n",
       "      <td>1.212787</td>\n",
       "      <td>0.271315</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>1.467220</td>\n",
       "      <td>0.332705</td>\n",
       "      <td>1.475147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PA_005no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>1.052086</td>\n",
       "      <td>271.537454</td>\n",
       "      <td>21.658928</td>\n",
       "      <td>129.618586</td>\n",
       "      <td>11.969402</td>\n",
       "      <td>1.212987</td>\n",
       "      <td>5.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>2.311154</td>\n",
       "      <td>1.010327</td>\n",
       "      <td>0.270293</td>\n",
       "      <td>1.332628</td>\n",
       "      <td>1.857653</td>\n",
       "      <td>0.562689</td>\n",
       "      <td>2.146590</td>\n",
       "      <td>1.508461</td>\n",
       "      <td>0.403692</td>\n",
       "      <td>1.557925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PA_006no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>0.739211</td>\n",
       "      <td>249.913724</td>\n",
       "      <td>16.760158</td>\n",
       "      <td>117.845775</td>\n",
       "      <td>2.424641</td>\n",
       "      <td>4.498472</td>\n",
       "      <td>16.214943</td>\n",
       "      <td>...</td>\n",
       "      <td>3.031446</td>\n",
       "      <td>1.277202</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>1.337109</td>\n",
       "      <td>1.138326</td>\n",
       "      <td>0.284632</td>\n",
       "      <td>1.042373</td>\n",
       "      <td>1.441762</td>\n",
       "      <td>0.329920</td>\n",
       "      <td>1.256846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Csoport Nem  SPI.raw_0_0  MFCC.mean_0_0_[E]_1  MFCC.std_0_0_[E]_1  \\\n",
       "0  PA_002no      PA  no     0.702423           226.727241           15.565275   \n",
       "1  PA_003no      PA  no     0.368337           188.198555           20.797340   \n",
       "2  PA_004no      PA  no     0.810142           245.252498           13.106253   \n",
       "3  PA_005no      PA  no     1.052086           271.537454           21.658928   \n",
       "4  PA_006no      PA  no     0.739211           249.913724           16.760158   \n",
       "\n",
       "   MFCC.range_0_0_[E]_1  HNR.mean_5_5_[E]  HNR.std_5_5_[E]  HNR.range_5_5_[E]  \\\n",
       "0            138.304191          7.702671         1.873980           8.800351   \n",
       "1            127.246116         -3.235416         1.841550           6.213561   \n",
       "2             94.247744          9.765168         1.553110           7.726234   \n",
       "3            129.618586         11.969402         1.212987           5.478905   \n",
       "4            117.845775          2.424641         4.498472          16.214943   \n",
       "\n",
       "   ...  IMF_ENTROPY_RATIO.range_0_0_[E-e:-i-2-y]  \\\n",
       "0  ...                                  2.379776   \n",
       "1  ...                                  0.950906   \n",
       "2  ...                                  2.337904   \n",
       "3  ...                                  2.311154   \n",
       "4  ...                                  3.031446   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.mean_0_0_[O-A:-o-u]  \\\n",
       "0                               1.229107   \n",
       "1                               1.054856   \n",
       "2                               1.175937   \n",
       "3                               1.010327   \n",
       "4                               1.277202   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.std_0_0_[O-A:-o-u]  \\\n",
       "0                              0.297684   \n",
       "1                              0.154813   \n",
       "2                              0.285692   \n",
       "3                              0.270293   \n",
       "4                              0.288863   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.range_0_0_[O-A:-o-u]  IMF_ENTROPY_RATIO.mean_0_0_[v-z-Z]  \\\n",
       "0                                1.656664                            1.342090   \n",
       "1                                0.754372                            1.022489   \n",
       "2                                1.626280                            1.212787   \n",
       "3                                1.332628                            1.857653   \n",
       "4                                1.337109                            1.138326   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.std_0_0_[v-z-Z]  IMF_ENTROPY_RATIO.range_0_0_[v-z-Z]  \\\n",
       "0                           0.599020                             2.269212   \n",
       "1                           0.159252                             0.522101   \n",
       "2                           0.271315                             0.985533   \n",
       "3                           0.562689                             2.146590   \n",
       "4                           0.284632                             1.042373   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.mean_0_0_[b-d-g-dz-dZ-d']  \\\n",
       "0                                     2.035604   \n",
       "1                                     1.098897   \n",
       "2                                     1.467220   \n",
       "3                                     1.508461   \n",
       "4                                     1.441762   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.std_0_0_[b-d-g-dz-dZ-d']  \\\n",
       "0                                    0.885508   \n",
       "1                                    0.111197   \n",
       "2                                    0.332705   \n",
       "3                                    0.403692   \n",
       "4                                    0.329920   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.range_0_0_[b-d-g-dz-dZ-d']  \n",
       "0                                      3.693024  \n",
       "1                                      0.488349  \n",
       "2                                      1.475147  \n",
       "3                                      1.557925  \n",
       "4                                      1.256846  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the data\n",
    "dataset = pd.read_csv('HC_PA_data.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "..  ..\n",
      "445  1\n",
      "446  0\n",
      "447  0\n",
      "448  0\n",
      "449  1\n",
      "\n",
      "[450 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "np.random.seed(42) # random seed is a number (or vector) used to initialize a pseudorandom number generator\n",
    "dataset = dataset.reindex(np.random.permutation(dataset.index))\n",
    "dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Selecting the training attributes(X) and the label(y)\n",
    "X = dataset.iloc[:, 3:52].values # X = dataset.iloc[:, np.r_[3:52]].values  lets you choose multiple coloumbs\n",
    "y = dataset.iloc[:,1].values\n",
    "\n",
    "# encode target\n",
    "encode = {\"HC\" : 0, \"PA\" : 1}\n",
    "decode = { 0 : \"HC\", 1 : \"PA\"}\n",
    "\n",
    "# Change target from string to binary value\n",
    "y = pd.DataFrame(y).replace(encode)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change y to categorical\n",
    "from keras.utils import np_utils\n",
    "y_categorical = np_utils.to_categorical(y)\n",
    "#print(y_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in columns with columns mean values \n",
    "imputer = Imputer(missing_values=np.nan, strategy = 'mean') # an instance of the class with these properties\n",
    "imputer = imputer.fit(X)         # we have to choose the columns with missing values\n",
    "X = imputer.transform(X)           # replace the X values for the columns averages\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size = 0.25, random_state = 0) \n",
    "\n",
    "# Feature Scaling to 0, 1 range\n",
    "from sklearn.preprocessing import MinMaxScaler # Normalization x_norm = (x- min(x))/(max(x)-min(x))\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_DNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_hidden_layer (Dense)   (None, 49)                2450      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "second_hidden_layer (Dense)  (None, 25)                1250      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "final_layer (Dense)          (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 3,752\n",
      "Trainable params: 3,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the network\n",
    "\n",
    "from keras.layers import InputLayer\n",
    "#print(X.shape[0])\n",
    "\n",
    "NUM_COLS = X.shape[1]\n",
    "NUM_ROWS = X.shape[0]\n",
    "#input_shape=(NUM_ROWS * NUM_COLS,)\n",
    "\n",
    "def get_sequential_dnn():\n",
    "    # create model\n",
    "    classifier = Sequential(name=\"Sequential_DNN\")  # future ANN classifier, now we initialize the different hidden layers \n",
    "    # ReLu activation function for the hidden layers\n",
    "    # Sigmoid for the final layer\n",
    "    \n",
    "    # input layer and the first hidden layer\n",
    "    classifier.add(InputLayer(input_shape=(X.shape[1])))\n",
    "    classifier.add(Dense(49, activation='relu', name=\"first_hidden_layer\", input_shape=(NUM_ROWS * NUM_COLS,)))\n",
    "    \n",
    "    \n",
    "    # tip: number of nodes in the hidden layers = average (number of nodes in the input layer and the number of nodes in the output layer) \n",
    "                                # so output_dim =(49+1)/2 = 25\n",
    "        \n",
    "                                # init -> initialize the weights randomly\n",
    "                                # input_dim = 49\n",
    "    \n",
    "    # Add a dropout layer for input layer\n",
    "    # More to read about dropout here: http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
    "    \n",
    "    classifier.add(Dropout(0.25))\n",
    "    \n",
    "    #Then we simply add the input-, hidden- and output-layers. \n",
    "    # Between them, we are using dropout to prevent overfitting. \n",
    "    # Note that you should always use a dropout rate between 20% and 50%. \n",
    "    # At every layer, we use “Dense” which means that the units are fully connected. \n",
    "    \n",
    "    # second hidden layer\n",
    "    #classifier.add(Dense(output_dim = 25, kernel_regularizer = regularizers.l2(0.01), activity_regularizer = regularizers.l1(0.01), init ='uniform', activation = 'relu', input_dim = 49))         \n",
    "    classifier.add(Dense(25, activation = 'relu', name=\"second_hidden_layer\"))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    #classifier.add(Dropout(0.5))\n",
    "        \n",
    "    # third hidden layer\n",
    "    #classifier.add(Dense(25, activation = 'relu', name=\"third_hidden_layer\"))\n",
    "    #classifier.add(Dropout(0.25))\n",
    "    #classifier.add(Dropout(0.5))\n",
    "    \n",
    "    # 4th hidden layer\n",
    "    #classifier.add(Dense(25, activation = 'relu', name=\"forth_hidden_layer\"))\n",
    "    #classifier.add(Dropout(0.25))\n",
    "    #classifier.add(Dropout(0.5))\n",
    "    \n",
    "    #classifier.add(Dense(output_dim = 2, activation = 'softmax', name=\"output_layer\"))\n",
    "    classifier.add(Dense(2, activation='softmax', name=\"final_layer\"))\n",
    "    return classifier\n",
    "\n",
    "classifier=get_sequential_dnn()\n",
    "classifier.summary()\n",
    "#print(len(classifier.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_metrics/metrics.py:51: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`inputs` is now automatically inferred\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_metrics/metrics.py:26: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.7151 - precision: 0.8139 - recall: 0.0627 - acc: 0.5935 - val_loss: 0.6923 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_acc: 0.5487\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6785 - precision: 0.4213 - recall: 0.0582 - acc: 0.5608 - val_loss: 0.6749 - val_precision: 0.8000 - val_recall: 0.0784 - val_acc: 0.5752\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6711 - precision: 0.4567 - recall: 0.1814 - acc: 0.5668 - val_loss: 0.6682 - val_precision: 0.6429 - val_recall: 0.1765 - val_acc: 0.5841\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6812 - precision: 0.4754 - recall: 0.1713 - acc: 0.5786 - val_loss: 0.6652 - val_precision: 0.6667 - val_recall: 0.3529 - val_acc: 0.6283\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6904 - precision: 0.4532 - recall: 0.2981 - acc: 0.5430 - val_loss: 0.6625 - val_precision: 0.7143 - val_recall: 0.4902 - val_acc: 0.6814\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6681 - precision: 0.5896 - recall: 0.3674 - acc: 0.6053 - val_loss: 0.6593 - val_precision: 0.6897 - val_recall: 0.3922 - val_acc: 0.6460\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6584 - precision: 0.6404 - recall: 0.3342 - acc: 0.6202 - val_loss: 0.6553 - val_precision: 0.7500 - val_recall: 0.2353 - val_acc: 0.6195\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6602 - precision: 0.5704 - recall: 0.2965 - acc: 0.6113 - val_loss: 0.6521 - val_precision: 0.8889 - val_recall: 0.1569 - val_acc: 0.6106\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6539 - precision: 0.5797 - recall: 0.2754 - acc: 0.6024 - val_loss: 0.6493 - val_precision: 1.0000 - val_recall: 0.0980 - val_acc: 0.5929\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6648 - precision: 0.7039 - recall: 0.2055 - acc: 0.6142 - val_loss: 0.6460 - val_precision: 1.0000 - val_recall: 0.0980 - val_acc: 0.5929\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6562 - precision: 0.6204 - recall: 0.1799 - acc: 0.6113 - val_loss: 0.6414 - val_precision: 1.0000 - val_recall: 0.1373 - val_acc: 0.6106\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6524 - precision: 0.6397 - recall: 0.2322 - acc: 0.6231 - val_loss: 0.6359 - val_precision: 0.9167 - val_recall: 0.2157 - val_acc: 0.6372\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6471 - precision: 0.7256 - recall: 0.2255 - acc: 0.6528 - val_loss: 0.6305 - val_precision: 0.9333 - val_recall: 0.2745 - val_acc: 0.6637\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6327 - precision: 0.6951 - recall: 0.3026 - acc: 0.6647 - val_loss: 0.6243 - val_precision: 0.8824 - val_recall: 0.2941 - val_acc: 0.6637\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6383 - precision: 0.6749 - recall: 0.3568 - acc: 0.6647 - val_loss: 0.6189 - val_precision: 0.8500 - val_recall: 0.3333 - val_acc: 0.6726\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6271 - precision: 0.7251 - recall: 0.4104 - acc: 0.6825 - val_loss: 0.6127 - val_precision: 0.8182 - val_recall: 0.3529 - val_acc: 0.6726\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6269 - precision: 0.6328 - recall: 0.3733 - acc: 0.6261 - val_loss: 0.6058 - val_precision: 0.7857 - val_recall: 0.4314 - val_acc: 0.6903\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6360 - precision: 0.6059 - recall: 0.3904 - acc: 0.6558 - val_loss: 0.5989 - val_precision: 0.8065 - val_recall: 0.4902 - val_acc: 0.7168\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6234 - precision: 0.6486 - recall: 0.5063 - acc: 0.6766 - val_loss: 0.5927 - val_precision: 0.8065 - val_recall: 0.4902 - val_acc: 0.7168\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6018 - precision: 0.6535 - recall: 0.4989 - acc: 0.6973 - val_loss: 0.5855 - val_precision: 0.7576 - val_recall: 0.4902 - val_acc: 0.6991\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6101 - precision: 0.6556 - recall: 0.5210 - acc: 0.6884 - val_loss: 0.5768 - val_precision: 0.7941 - val_recall: 0.5294 - val_acc: 0.7257\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5955 - precision: 0.6472 - recall: 0.4744 - acc: 0.6825 - val_loss: 0.5680 - val_precision: 0.8286 - val_recall: 0.5686 - val_acc: 0.7522\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5823 - precision: 0.7107 - recall: 0.5285 - acc: 0.7033 - val_loss: 0.5585 - val_precision: 0.8108 - val_recall: 0.5882 - val_acc: 0.7522\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5961 - precision: 0.7011 - recall: 0.5605 - acc: 0.7033 - val_loss: 0.5492 - val_precision: 0.7561 - val_recall: 0.6078 - val_acc: 0.7345\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5781 - precision: 0.6982 - recall: 0.5414 - acc: 0.7122 - val_loss: 0.5413 - val_precision: 0.7561 - val_recall: 0.6078 - val_acc: 0.7345\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5986 - precision: 0.6384 - recall: 0.5550 - acc: 0.7033 - val_loss: 0.5347 - val_precision: 0.7619 - val_recall: 0.6275 - val_acc: 0.7434\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5979 - precision: 0.6124 - recall: 0.5255 - acc: 0.6677 - val_loss: 0.5280 - val_precision: 0.7556 - val_recall: 0.6667 - val_acc: 0.7522\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5696 - precision: 0.6974 - recall: 0.6247 - acc: 0.7359 - val_loss: 0.5221 - val_precision: 0.7660 - val_recall: 0.7059 - val_acc: 0.7699\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5819 - precision: 0.6490 - recall: 0.6248 - acc: 0.7300 - val_loss: 0.5165 - val_precision: 0.7600 - val_recall: 0.7451 - val_acc: 0.7788\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5502 - precision: 0.6964 - recall: 0.6292 - acc: 0.6884 - val_loss: 0.5104 - val_precision: 0.7556 - val_recall: 0.6667 - val_acc: 0.7522\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5760 - precision: 0.6965 - recall: 0.5818 - acc: 0.6944 - val_loss: 0.5065 - val_precision: 0.7674 - val_recall: 0.6471 - val_acc: 0.7522\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5544 - precision: 0.7324 - recall: 0.6539 - acc: 0.7211 - val_loss: 0.5026 - val_precision: 0.7805 - val_recall: 0.6275 - val_acc: 0.7522\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5522 - precision: 0.7059 - recall: 0.6087 - acc: 0.7300 - val_loss: 0.4972 - val_precision: 0.7778 - val_recall: 0.6863 - val_acc: 0.7699\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5482 - precision: 0.7068 - recall: 0.6307 - acc: 0.7300 - val_loss: 0.4920 - val_precision: 0.7800 - val_recall: 0.7647 - val_acc: 0.7965\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5273 - precision: 0.6868 - recall: 0.6275 - acc: 0.7270 - val_loss: 0.4859 - val_precision: 0.8000 - val_recall: 0.7843 - val_acc: 0.8142\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5236 - precision: 0.7390 - recall: 0.6957 - acc: 0.7507 - val_loss: 0.4800 - val_precision: 0.7826 - val_recall: 0.7059 - val_acc: 0.7788\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5334 - precision: 0.7449 - recall: 0.6322 - acc: 0.7537 - val_loss: 0.4760 - val_precision: 0.8250 - val_recall: 0.6471 - val_acc: 0.7788\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5281 - precision: 0.7197 - recall: 0.5428 - acc: 0.7270 - val_loss: 0.4671 - val_precision: 0.8293 - val_recall: 0.6667 - val_acc: 0.7876\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5159 - precision: 0.7311 - recall: 0.6683 - acc: 0.7507 - val_loss: 0.4572 - val_precision: 0.7959 - val_recall: 0.7647 - val_acc: 0.8053\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5336 - precision: 0.7154 - recall: 0.6565 - acc: 0.7389 - val_loss: 0.4508 - val_precision: 0.7593 - val_recall: 0.8039 - val_acc: 0.7965\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5292 - precision: 0.6951 - recall: 0.6851 - acc: 0.7389 - val_loss: 0.4453 - val_precision: 0.8039 - val_recall: 0.8039 - val_acc: 0.8230\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5272 - precision: 0.7076 - recall: 0.6589 - acc: 0.7537 - val_loss: 0.4417 - val_precision: 0.8039 - val_recall: 0.8039 - val_acc: 0.8230\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5271 - precision: 0.7343 - recall: 0.6632 - acc: 0.7596 - val_loss: 0.4392 - val_precision: 0.8039 - val_recall: 0.8039 - val_acc: 0.8230\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5122 - precision: 0.7126 - recall: 0.6450 - acc: 0.7359 - val_loss: 0.4380 - val_precision: 0.8163 - val_recall: 0.7843 - val_acc: 0.8230\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5084 - precision: 0.7322 - recall: 0.6386 - acc: 0.7389 - val_loss: 0.4376 - val_precision: 0.8261 - val_recall: 0.7451 - val_acc: 0.8142\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5206 - precision: 0.7016 - recall: 0.6254 - acc: 0.7507 - val_loss: 0.4371 - val_precision: 0.8409 - val_recall: 0.7255 - val_acc: 0.8142\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5084 - precision: 0.7349 - recall: 0.6759 - acc: 0.7507 - val_loss: 0.4340 - val_precision: 0.8409 - val_recall: 0.7255 - val_acc: 0.8142\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5120 - precision: 0.7368 - recall: 0.6425 - acc: 0.7507 - val_loss: 0.4309 - val_precision: 0.8269 - val_recall: 0.8431 - val_acc: 0.8496\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5015 - precision: 0.7343 - recall: 0.6678 - acc: 0.7626 - val_loss: 0.4294 - val_precision: 0.8269 - val_recall: 0.8431 - val_acc: 0.8496\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4756 - precision: 0.7413 - recall: 0.7408 - acc: 0.7893 - val_loss: 0.4256 - val_precision: 0.8333 - val_recall: 0.7843 - val_acc: 0.8319\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4969 - precision: 0.7211 - recall: 0.6930 - acc: 0.7537 - val_loss: 0.4220 - val_precision: 0.8478 - val_recall: 0.7647 - val_acc: 0.8319\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5005 - precision: 0.7544 - recall: 0.6942 - acc: 0.7715 - val_loss: 0.4198 - val_precision: 0.8409 - val_recall: 0.7255 - val_acc: 0.8142\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5108 - precision: 0.7492 - recall: 0.6676 - acc: 0.7596 - val_loss: 0.4213 - val_precision: 0.8750 - val_recall: 0.6863 - val_acc: 0.8142\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4916 - precision: 0.7345 - recall: 0.6342 - acc: 0.7596 - val_loss: 0.4169 - val_precision: 0.8636 - val_recall: 0.7451 - val_acc: 0.8319\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4909 - precision: 0.7375 - recall: 0.6655 - acc: 0.7745 - val_loss: 0.4134 - val_precision: 0.8478 - val_recall: 0.7647 - val_acc: 0.8319\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4720 - precision: 0.7222 - recall: 0.6880 - acc: 0.7537 - val_loss: 0.4090 - val_precision: 0.8511 - val_recall: 0.7843 - val_acc: 0.8407\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5068 - precision: 0.7202 - recall: 0.6802 - acc: 0.7596 - val_loss: 0.4056 - val_precision: 0.8333 - val_recall: 0.7843 - val_acc: 0.8319\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4766 - precision: 0.7076 - recall: 0.6640 - acc: 0.7448 - val_loss: 0.4025 - val_precision: 0.8667 - val_recall: 0.7647 - val_acc: 0.8407\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4811 - precision: 0.7546 - recall: 0.7168 - acc: 0.7864 - val_loss: 0.4016 - val_precision: 0.8864 - val_recall: 0.7647 - val_acc: 0.8496\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4798 - precision: 0.7826 - recall: 0.6261 - acc: 0.7745 - val_loss: 0.3986 - val_precision: 0.8864 - val_recall: 0.7647 - val_acc: 0.8496\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4686 - precision: 0.7340 - recall: 0.6880 - acc: 0.7715 - val_loss: 0.3967 - val_precision: 0.8864 - val_recall: 0.7647 - val_acc: 0.8496\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4734 - precision: 0.7311 - recall: 0.7186 - acc: 0.7804 - val_loss: 0.3985 - val_precision: 0.8837 - val_recall: 0.7451 - val_acc: 0.8407\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4645 - precision: 0.7593 - recall: 0.6450 - acc: 0.7656 - val_loss: 0.3941 - val_precision: 0.8864 - val_recall: 0.7647 - val_acc: 0.8496\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4675 - precision: 0.7426 - recall: 0.7166 - acc: 0.7893 - val_loss: 0.3905 - val_precision: 0.8696 - val_recall: 0.7843 - val_acc: 0.8496\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4453 - precision: 0.7476 - recall: 0.6742 - acc: 0.7923 - val_loss: 0.3865 - val_precision: 0.8723 - val_recall: 0.8039 - val_acc: 0.8584\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4638 - precision: 0.7376 - recall: 0.7359 - acc: 0.7715 - val_loss: 0.3835 - val_precision: 0.8723 - val_recall: 0.8039 - val_acc: 0.8584\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4595 - precision: 0.7864 - recall: 0.7262 - acc: 0.7804 - val_loss: 0.3831 - val_precision: 0.8889 - val_recall: 0.7843 - val_acc: 0.8584\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4799 - precision: 0.7642 - recall: 0.6782 - acc: 0.7656 - val_loss: 0.3883 - val_precision: 0.8837 - val_recall: 0.7451 - val_acc: 0.8407\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4497 - precision: 0.7859 - recall: 0.6904 - acc: 0.7864 - val_loss: 0.3862 - val_precision: 0.8837 - val_recall: 0.7451 - val_acc: 0.8407\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4599 - precision: 0.7673 - recall: 0.6690 - acc: 0.7923 - val_loss: 0.3821 - val_precision: 0.8723 - val_recall: 0.8039 - val_acc: 0.8584\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4375 - precision: 0.7738 - recall: 0.7079 - acc: 0.7923 - val_loss: 0.3814 - val_precision: 0.8750 - val_recall: 0.8235 - val_acc: 0.8673\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4377 - precision: 0.7464 - recall: 0.7225 - acc: 0.7804 - val_loss: 0.3777 - val_precision: 0.8750 - val_recall: 0.8235 - val_acc: 0.8673\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4462 - precision: 0.7807 - recall: 0.7295 - acc: 0.7864 - val_loss: 0.3781 - val_precision: 0.8810 - val_recall: 0.7255 - val_acc: 0.8319\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4218 - precision: 0.7970 - recall: 0.7430 - acc: 0.7923 - val_loss: 0.3804 - val_precision: 0.8780 - val_recall: 0.7059 - val_acc: 0.8230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4606 - precision: 0.7494 - recall: 0.6493 - acc: 0.7715 - val_loss: 0.3755 - val_precision: 0.8750 - val_recall: 0.8235 - val_acc: 0.8673\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4560 - precision: 0.7648 - recall: 0.7250 - acc: 0.7804 - val_loss: 0.3794 - val_precision: 0.8750 - val_recall: 0.8235 - val_acc: 0.8673\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4584 - precision: 0.7555 - recall: 0.7280 - acc: 0.7923 - val_loss: 0.3831 - val_precision: 0.8696 - val_recall: 0.7843 - val_acc: 0.8496\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4526 - precision: 0.7191 - recall: 0.7233 - acc: 0.7685 - val_loss: 0.3860 - val_precision: 0.8837 - val_recall: 0.7451 - val_acc: 0.8407\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4325 - precision: 0.7866 - recall: 0.7017 - acc: 0.8042 - val_loss: 0.3880 - val_precision: 0.8605 - val_recall: 0.7255 - val_acc: 0.8230\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4204 - precision: 0.8410 - recall: 0.7508 - acc: 0.8249 - val_loss: 0.3831 - val_precision: 0.8542 - val_recall: 0.8039 - val_acc: 0.8496\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4202 - precision: 0.7430 - recall: 0.7104 - acc: 0.8012 - val_loss: 0.3822 - val_precision: 0.8864 - val_recall: 0.7647 - val_acc: 0.8496\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4237 - precision: 0.7686 - recall: 0.7478 - acc: 0.7745 - val_loss: 0.3750 - val_precision: 0.8511 - val_recall: 0.7843 - val_acc: 0.8407\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4273 - precision: 0.8265 - recall: 0.7506 - acc: 0.8071 - val_loss: 0.3687 - val_precision: 0.8571 - val_recall: 0.8235 - val_acc: 0.8584\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4221 - precision: 0.7230 - recall: 0.7644 - acc: 0.7893 - val_loss: 0.3708 - val_precision: 0.8571 - val_recall: 0.8235 - val_acc: 0.8584\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4336 - precision: 0.7775 - recall: 0.6844 - acc: 0.7804 - val_loss: 0.3775 - val_precision: 0.8478 - val_recall: 0.7647 - val_acc: 0.8319\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4137 - precision: 0.8012 - recall: 0.7319 - acc: 0.8071 - val_loss: 0.3793 - val_precision: 0.8667 - val_recall: 0.7647 - val_acc: 0.8407\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4290 - precision: 0.7777 - recall: 0.7214 - acc: 0.7893 - val_loss: 0.3768 - val_precision: 0.8542 - val_recall: 0.8039 - val_acc: 0.8496\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4230 - precision: 0.7645 - recall: 0.7636 - acc: 0.8131 - val_loss: 0.3769 - val_precision: 0.8696 - val_recall: 0.7843 - val_acc: 0.8496\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4041 - precision: 0.7899 - recall: 0.7714 - acc: 0.8338 - val_loss: 0.3757 - val_precision: 0.8889 - val_recall: 0.7843 - val_acc: 0.8584\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3897 - precision: 0.8105 - recall: 0.7396 - acc: 0.8220 - val_loss: 0.3714 - val_precision: 0.8889 - val_recall: 0.7843 - val_acc: 0.8584\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4100 - precision: 0.8147 - recall: 0.7101 - acc: 0.8071 - val_loss: 0.3645 - val_precision: 0.8696 - val_recall: 0.7843 - val_acc: 0.8496\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4054 - precision: 0.8424 - recall: 0.7764 - acc: 0.8279 - val_loss: 0.3635 - val_precision: 0.8696 - val_recall: 0.7843 - val_acc: 0.8496\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4021 - precision: 0.7704 - recall: 0.7271 - acc: 0.8012 - val_loss: 0.3777 - val_precision: 0.9024 - val_recall: 0.7255 - val_acc: 0.8407\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3931 - precision: 0.8597 - recall: 0.7660 - acc: 0.8338 - val_loss: 0.3672 - val_precision: 0.8864 - val_recall: 0.7647 - val_acc: 0.8496\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3839 - precision: 0.8758 - recall: 0.7703 - acc: 0.8516 - val_loss: 0.3599 - val_precision: 0.8696 - val_recall: 0.7843 - val_acc: 0.8496\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3831 - precision: 0.8211 - recall: 0.8419 - acc: 0.8279 - val_loss: 0.3587 - val_precision: 0.8936 - val_recall: 0.8235 - val_acc: 0.8761\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3856 - precision: 0.7982 - recall: 0.7608 - acc: 0.8279 - val_loss: 0.3665 - val_precision: 0.8889 - val_recall: 0.7843 - val_acc: 0.8584\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4056 - precision: 0.8127 - recall: 0.7291 - acc: 0.8160 - val_loss: 0.3706 - val_precision: 0.9070 - val_recall: 0.7647 - val_acc: 0.8584\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3692 - precision: 0.8341 - recall: 0.7413 - acc: 0.8220 - val_loss: 0.3729 - val_precision: 0.9070 - val_recall: 0.7647 - val_acc: 0.8584\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3939 - precision: 0.8233 - recall: 0.7306 - acc: 0.8220 - val_loss: 0.3654 - val_precision: 0.8889 - val_recall: 0.7843 - val_acc: 0.8584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0b5acffa00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128 #  128\n",
    "EPOCHS = 100\n",
    "\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras_metrics.precision(), keras_metrics.recall(), 'acc'])\n",
    "        \n",
    "    # Fit the model    \n",
    "    #classifier.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=150, verbose=0) \n",
    "\n",
    "classifier.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data = (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3654383420944214\n",
      "Test accuracy: 0.8584070801734924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.3654383420944214,\n",
       " 'precision': 0.7940705418586731,\n",
       " 'recall': 0.7345297932624817,\n",
       " 'acc': 0.8584070801734924}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "# be carefull with this shady function, as the documentation might be misleading \n",
    "# https://www.tutorialspoint.com/keras/keras_model_evaluation_and_prediction.htm\n",
    "# score[1] is actually the precision metric in this case, and not the accuracy\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[3])\n",
    "\n",
    "dict(zip(classifier.metrics_names, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0\n",
      " 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 1 1\n",
      " 0 0]\n",
      "Test [0. 1.]\n",
      "Test 1\n",
      "Test [1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting test labels    \n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "pred = pred.round().astype(int)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "#pred = pred.reshape(y_test.shape)\n",
    "\n",
    "print(\"Predicted:\", pred)\n",
    "print(\"Test\", y_test[0])\n",
    "print(\"Test\", y_test[0].argmax(0))\n",
    "\n",
    "# one-hot to simple test format\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "print(\"Test\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: ['PA' 'HC' 'PA' 'PA' 'PA' 'HC' 'PA' 'PA' 'PA' 'HC' 'PA' 'HC' 'HC' 'PA'\n",
      " 'PA' 'PA' 'HC' 'HC' 'PA' 'PA' 'HC' 'HC' 'PA' 'PA' 'PA' 'HC' 'PA' 'PA'\n",
      " 'PA' 'PA' 'PA' 'HC' 'PA' 'HC' 'PA' 'PA' 'PA' 'PA' 'PA' 'PA' 'PA' 'HC'\n",
      " 'PA' 'HC' 'PA' 'HC' 'HC' 'HC' 'PA' 'PA' 'PA' 'PA' 'HC' 'HC' 'PA' 'HC'\n",
      " 'PA' 'PA' 'PA' 'HC' 'HC' 'PA' 'HC' 'PA' 'HC' 'HC' 'PA' 'PA' 'PA' 'HC'\n",
      " 'PA' 'PA' 'PA' 'HC' 'PA' 'HC' 'HC' 'PA' 'PA' 'HC' 'HC' 'HC' 'PA' 'PA'\n",
      " 'HC' 'HC' 'HC' 'PA' 'HC' 'PA' 'PA' 'PA' 'HC' 'PA' 'HC' 'PA' 'PA' 'HC'\n",
      " 'PA' 'PA' 'PA' 'PA' 'PA' 'HC' 'PA' 'PA' 'HC' 'HC' 'HC' 'PA' 'PA' 'HC'\n",
      " 'HC']\n",
      "Test ['PA' 'HC' 'PA' 'PA' 'PA' 'PA' 'PA' 'HC' 'PA' 'PA' 'PA' 'PA' 'HC' 'HC'\n",
      " 'HC' 'PA' 'HC' 'HC' 'PA' 'PA' 'HC' 'HC' 'PA' 'HC' 'PA' 'HC' 'PA' 'PA'\n",
      " 'PA' 'PA' 'PA' 'PA' 'PA' 'HC' 'PA' 'PA' 'PA' 'PA' 'PA' 'PA' 'PA' 'HC'\n",
      " 'PA' 'HC' 'PA' 'HC' 'HC' 'PA' 'PA' 'PA' 'PA' 'HC' 'HC' 'HC' 'PA' 'HC'\n",
      " 'PA' 'PA' 'PA' 'HC' 'HC' 'PA' 'HC' 'HC' 'HC' 'HC' 'PA' 'PA' 'PA' 'HC'\n",
      " 'PA' 'PA' 'PA' 'HC' 'PA' 'HC' 'HC' 'PA' 'HC' 'HC' 'HC' 'HC' 'PA' 'HC'\n",
      " 'HC' 'HC' 'HC' 'PA' 'HC' 'PA' 'PA' 'HC' 'HC' 'HC' 'HC' 'PA' 'PA' 'HC'\n",
      " 'PA' 'PA' 'PA' 'PA' 'HC' 'HC' 'PA' 'PA' 'HC' 'HC' 'HC' 'PA' 'PA' 'HC'\n",
      " 'HC']\n"
     ]
    }
   ],
   "source": [
    "pred = pred.astype('str')\n",
    "y_test = y_test.astype('str')\n",
    "pred[pred == '0'] = decode[0]\n",
    "pred[pred == '1'] = decode[1]\n",
    "y_test[y_test == '0'] = decode[0]\n",
    "y_test[y_test == '1'] = decode[1]\n",
    "\n",
    "print(\"Predicted:\", pred)\n",
    "print(\"Test\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         40   5   45\n",
      "PA         11  57   68\n",
      "All        51  62  113\n"
     ]
    }
   ],
   "source": [
    "y_actu = pd.Series(y_test, name='True')\n",
    "y_pred = pd.Series(pred, name='Pred')\n",
    "df_confusion = pd.crosstab(y_pred, y_actu, colnames=['True'], rownames=['Predicted'], margins=True)\n",
    "print(\"\")\n",
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  5]\n",
      " [11 57]]\n"
     ]
    }
   ],
   "source": [
    "cm_final = df_confusion.iloc[0:-1].values\n",
    "\n",
    "cm_final = cm_final[:,[0,1]]\n",
    "print(cm_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Statistical measures calculated from Confusion Matrix #\n",
    "#########################################################\n",
    "import math\n",
    "\n",
    "# (tp + tn) / (tp + fp + tn + fn)\n",
    "def get_accuracy(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    #print([tp, fp], [fn, tn])\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "# sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "# tp / (tp + fn)\n",
    "def get_recall(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "# precision or positive predictive value (PPV)\n",
    "# tp / (tp + fp)\n",
    "def get_precision(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "# harmonic mean of precision and sensitivity\n",
    "# 2*((precision*recall)/(precision+recall))\n",
    "def get_f1score(mx):\n",
    "    return 2*((get_precision(mx)*get_recall(mx))/(get_precision(mx)+get_recall(mx)))\n",
    "\n",
    "# specificity, selectivity or true negative rate (TNR)\n",
    "# \n",
    "def get_specificity(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def get_sensitivity(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "def get_MCC(mx):\n",
    "    # Matthews Correlation Coefficient (MCC)\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    \n",
    "    return (tp*tn-fp*fn)/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________\n",
      "\n",
      "Accuracy: 0.858407\n",
      "Matthews Correlation Coefficient: 0.715300\n",
      "\n",
      "For class HC: \n",
      "\n",
      "Recall: 0.784314\n",
      "Precision: 0.888889\n",
      "F1 score: 0.833333\n",
      "Specificity: 0.784314\n",
      "Sensitivity: 0.919355\n",
      "\n",
      "For class PA: \n",
      "\n",
      "Recall: 0.919355\n",
      "Precision: 0.838235\n",
      "F1 score: 0.876923\n",
      "Specificity: 0.919355\n",
      "Sensitivity: 0.784314\n"
     ]
    }
   ],
   "source": [
    "# Calculating statistical measures from Confusion Matrix\n",
    "mx = cm_final\n",
    "print(\"__________________________________\")\n",
    "print(\"\")\n",
    "print('Accuracy: %f' % get_accuracy(mx))\n",
    "print('Matthews Correlation Coefficient: %f' % get_MCC(mx))\n",
    "print(\"\")\n",
    "\n",
    "print(\"For class {}: \".format(df_confusion.columns[0]) )\n",
    "print(\"\")\n",
    "print('Recall: %f' % get_recall(mx))\n",
    "print('Precision: %f' % get_precision(mx))\n",
    "print('F1 score: %f' % get_f1score(mx))\n",
    "print('Specificity: %f' % get_specificity(mx))\n",
    "print('Sensitivity: %f' % get_sensitivity(mx))\n",
    "\n",
    "[tn, fp], [fn, tp] = mx\n",
    "mx_ = [tp, fn],[fp, tn]\n",
    "print(\"\")\n",
    "print(\"For class {}: \".format(df_confusion.columns[1]) )\n",
    "print(\"\")\n",
    "print('Recall: %f' % get_recall(mx_))\n",
    "print('Precision: %f' % get_precision(mx_))\n",
    "print('F1 score: %f' % get_f1score(mx_))\n",
    "print('Specificity: %f' % get_specificity(mx_))\n",
    "print('Sensitivity: %f' % get_sensitivity(mx_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
