{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected Deep Neural Network for k-fold cross validation\n",
    "\n",
    "### My updated template for a binary classification, with a confusion matrix\n",
    "\n",
    "### Metrics given:\n",
    "\n",
    "Accuracy, Matthews Correlation Coefficient\n",
    "\n",
    "For each class: Recall, Precision, F1 score, Specificity, Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import regularizers, losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.impute import SimpleImputer as Imputer #class\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "import keras_metrics\n",
    "from keras import optimizers\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # https://jovianlin.io/feature-scaling/\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Csoport</th>\n",
       "      <th>Nem</th>\n",
       "      <th>SPI.raw_0_0</th>\n",
       "      <th>MFCC.mean_0_0_[E]_1</th>\n",
       "      <th>MFCC.std_0_0_[E]_1</th>\n",
       "      <th>MFCC.range_0_0_[E]_1</th>\n",
       "      <th>HNR.mean_5_5_[E]</th>\n",
       "      <th>HNR.std_5_5_[E]</th>\n",
       "      <th>HNR.range_5_5_[E]</th>\n",
       "      <th>...</th>\n",
       "      <th>IMF_ENTROPY_RATIO.range_0_0_[E-e:-i-2-y]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.mean_0_0_[O-A:-o-u]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.std_0_0_[O-A:-o-u]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.range_0_0_[O-A:-o-u]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.mean_0_0_[v-z-Z]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.std_0_0_[v-z-Z]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.range_0_0_[v-z-Z]</th>\n",
       "      <th>IMF_ENTROPY_RATIO.mean_0_0_[b-d-g-dz-dZ-d']</th>\n",
       "      <th>IMF_ENTROPY_RATIO.std_0_0_[b-d-g-dz-dZ-d']</th>\n",
       "      <th>IMF_ENTROPY_RATIO.range_0_0_[b-d-g-dz-dZ-d']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA_002no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>0.702423</td>\n",
       "      <td>226.727241</td>\n",
       "      <td>15.565275</td>\n",
       "      <td>138.304191</td>\n",
       "      <td>7.702671</td>\n",
       "      <td>1.873980</td>\n",
       "      <td>8.800351</td>\n",
       "      <td>...</td>\n",
       "      <td>2.379776</td>\n",
       "      <td>1.229107</td>\n",
       "      <td>0.297684</td>\n",
       "      <td>1.656664</td>\n",
       "      <td>1.342090</td>\n",
       "      <td>0.599020</td>\n",
       "      <td>2.269212</td>\n",
       "      <td>2.035604</td>\n",
       "      <td>0.885508</td>\n",
       "      <td>3.693024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA_003no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>0.368337</td>\n",
       "      <td>188.198555</td>\n",
       "      <td>20.797340</td>\n",
       "      <td>127.246116</td>\n",
       "      <td>-3.235416</td>\n",
       "      <td>1.841550</td>\n",
       "      <td>6.213561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950906</td>\n",
       "      <td>1.054856</td>\n",
       "      <td>0.154813</td>\n",
       "      <td>0.754372</td>\n",
       "      <td>1.022489</td>\n",
       "      <td>0.159252</td>\n",
       "      <td>0.522101</td>\n",
       "      <td>1.098897</td>\n",
       "      <td>0.111197</td>\n",
       "      <td>0.488349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PA_004no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>0.810142</td>\n",
       "      <td>245.252498</td>\n",
       "      <td>13.106253</td>\n",
       "      <td>94.247744</td>\n",
       "      <td>9.765168</td>\n",
       "      <td>1.553110</td>\n",
       "      <td>7.726234</td>\n",
       "      <td>...</td>\n",
       "      <td>2.337904</td>\n",
       "      <td>1.175937</td>\n",
       "      <td>0.285692</td>\n",
       "      <td>1.626280</td>\n",
       "      <td>1.212787</td>\n",
       "      <td>0.271315</td>\n",
       "      <td>0.985533</td>\n",
       "      <td>1.467220</td>\n",
       "      <td>0.332705</td>\n",
       "      <td>1.475147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PA_005no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>1.052086</td>\n",
       "      <td>271.537454</td>\n",
       "      <td>21.658928</td>\n",
       "      <td>129.618586</td>\n",
       "      <td>11.969402</td>\n",
       "      <td>1.212987</td>\n",
       "      <td>5.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>2.311154</td>\n",
       "      <td>1.010327</td>\n",
       "      <td>0.270293</td>\n",
       "      <td>1.332628</td>\n",
       "      <td>1.857653</td>\n",
       "      <td>0.562689</td>\n",
       "      <td>2.146590</td>\n",
       "      <td>1.508461</td>\n",
       "      <td>0.403692</td>\n",
       "      <td>1.557925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PA_006no</td>\n",
       "      <td>PA</td>\n",
       "      <td>no</td>\n",
       "      <td>0.739211</td>\n",
       "      <td>249.913724</td>\n",
       "      <td>16.760158</td>\n",
       "      <td>117.845775</td>\n",
       "      <td>2.424641</td>\n",
       "      <td>4.498472</td>\n",
       "      <td>16.214943</td>\n",
       "      <td>...</td>\n",
       "      <td>3.031446</td>\n",
       "      <td>1.277202</td>\n",
       "      <td>0.288863</td>\n",
       "      <td>1.337109</td>\n",
       "      <td>1.138326</td>\n",
       "      <td>0.284632</td>\n",
       "      <td>1.042373</td>\n",
       "      <td>1.441762</td>\n",
       "      <td>0.329920</td>\n",
       "      <td>1.256846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Csoport Nem  SPI.raw_0_0  MFCC.mean_0_0_[E]_1  MFCC.std_0_0_[E]_1  \\\n",
       "0  PA_002no      PA  no     0.702423           226.727241           15.565275   \n",
       "1  PA_003no      PA  no     0.368337           188.198555           20.797340   \n",
       "2  PA_004no      PA  no     0.810142           245.252498           13.106253   \n",
       "3  PA_005no      PA  no     1.052086           271.537454           21.658928   \n",
       "4  PA_006no      PA  no     0.739211           249.913724           16.760158   \n",
       "\n",
       "   MFCC.range_0_0_[E]_1  HNR.mean_5_5_[E]  HNR.std_5_5_[E]  HNR.range_5_5_[E]  \\\n",
       "0            138.304191          7.702671         1.873980           8.800351   \n",
       "1            127.246116         -3.235416         1.841550           6.213561   \n",
       "2             94.247744          9.765168         1.553110           7.726234   \n",
       "3            129.618586         11.969402         1.212987           5.478905   \n",
       "4            117.845775          2.424641         4.498472          16.214943   \n",
       "\n",
       "   ...  IMF_ENTROPY_RATIO.range_0_0_[E-e:-i-2-y]  \\\n",
       "0  ...                                  2.379776   \n",
       "1  ...                                  0.950906   \n",
       "2  ...                                  2.337904   \n",
       "3  ...                                  2.311154   \n",
       "4  ...                                  3.031446   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.mean_0_0_[O-A:-o-u]  \\\n",
       "0                               1.229107   \n",
       "1                               1.054856   \n",
       "2                               1.175937   \n",
       "3                               1.010327   \n",
       "4                               1.277202   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.std_0_0_[O-A:-o-u]  \\\n",
       "0                              0.297684   \n",
       "1                              0.154813   \n",
       "2                              0.285692   \n",
       "3                              0.270293   \n",
       "4                              0.288863   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.range_0_0_[O-A:-o-u]  IMF_ENTROPY_RATIO.mean_0_0_[v-z-Z]  \\\n",
       "0                                1.656664                            1.342090   \n",
       "1                                0.754372                            1.022489   \n",
       "2                                1.626280                            1.212787   \n",
       "3                                1.332628                            1.857653   \n",
       "4                                1.337109                            1.138326   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.std_0_0_[v-z-Z]  IMF_ENTROPY_RATIO.range_0_0_[v-z-Z]  \\\n",
       "0                           0.599020                             2.269212   \n",
       "1                           0.159252                             0.522101   \n",
       "2                           0.271315                             0.985533   \n",
       "3                           0.562689                             2.146590   \n",
       "4                           0.284632                             1.042373   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.mean_0_0_[b-d-g-dz-dZ-d']  \\\n",
       "0                                     2.035604   \n",
       "1                                     1.098897   \n",
       "2                                     1.467220   \n",
       "3                                     1.508461   \n",
       "4                                     1.441762   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.std_0_0_[b-d-g-dz-dZ-d']  \\\n",
       "0                                    0.885508   \n",
       "1                                    0.111197   \n",
       "2                                    0.332705   \n",
       "3                                    0.403692   \n",
       "4                                    0.329920   \n",
       "\n",
       "   IMF_ENTROPY_RATIO.range_0_0_[b-d-g-dz-dZ-d']  \n",
       "0                                      3.693024  \n",
       "1                                      0.488349  \n",
       "2                                      1.475147  \n",
       "3                                      1.557925  \n",
       "4                                      1.256846  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the data\n",
    "dataset = pd.read_csv('HC_PA_data.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "np.random.seed(42) # random seed is a number (or vector) used to initialize a pseudorandom number generator\n",
    "dataset = dataset.reindex(np.random.permutation(dataset.index))\n",
    "dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Selecting the training attributes(X) and the label(y)\n",
    "X = dataset.iloc[:, 3:52].values # X = dataset.iloc[:, np.r_[3:52]].values  lets you choose multiple coloumbs\n",
    "y = dataset.iloc[:,1].values\n",
    "\n",
    "# encode target\n",
    "encode = {\"HC\" : 0, \"PA\" : 1}\n",
    "decode = { 0 : \"HC\", 1 : \"PA\"}\n",
    "\n",
    "y = pd.DataFrame(y).replace(encode)\n",
    "                     \n",
    "from keras.utils import np_utils\n",
    "y_categorical = np_utils.to_categorical(y)\n",
    "\n",
    "# Replace NaN values in columns with columns mean values \n",
    "imputer = Imputer(missing_values=np.nan, strategy = 'mean') # an instance of the class with these properties\n",
    "imputer = imputer.fit(X)         # we have to choose the columns with missing values\n",
    "X = imputer.transform(X)           # replace the X values for the columns averages\n",
    "\n",
    "# Feature Scaling\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler() \n",
    "scaled_data = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential_DNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_hidden_layer (Dense)   (None, 49)                2450      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "second_hidden_layer (Dense)  (None, 25)                1250      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "third_hidden_layer (Dense)   (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "forth_hidden_layer (Dense)   (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "final_layer (Dense)          (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 5,052\n",
      "Trainable params: 5,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the network\n",
    "\n",
    "from keras.layers import InputLayer\n",
    "#print(X.shape[0])\n",
    "\n",
    "NUM_COLS = X.shape[1]\n",
    "NUM_ROWS = X.shape[0]\n",
    "#input_shape=(NUM_ROWS * NUM_COLS,)\n",
    "\n",
    "def get_sequential_dnn():\n",
    "    # create model\n",
    "    classifier = Sequential(name=\"Sequential_DNN\")  # future ANN classifier, now we initialize the different hidden layers \n",
    "    # ReLu activation function for the hidden layers\n",
    "    # Sigmoid for the final layer\n",
    "    \n",
    "    # input layer and the first hidden layer\n",
    "    classifier.add(InputLayer(input_shape=(X.shape[1])))\n",
    "    classifier.add(Dense(49, activation='relu', name=\"first_hidden_layer\", input_shape=(NUM_ROWS * NUM_COLS,)))\n",
    "    \n",
    "    \n",
    "    # tip: number of nodes in the hidden layers = average (number of nodes in the input layer and the number of nodes in the output layer) \n",
    "                                # so output_dim =(49+1)/2 = 25\n",
    "        \n",
    "                                # init -> initialize the weights randomly\n",
    "                                # input_dim = 49\n",
    "    \n",
    "    # Add a dropout layer for input layer\n",
    "    # More to read about dropout here: http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
    "    \n",
    "    classifier.add(Dropout(0.25))\n",
    "    \n",
    "    #Then we simply add the input-, hidden- and output-layers. \n",
    "    # Between them, we are using dropout to prevent overfitting. \n",
    "    # Note that you should always use a dropout rate between 20% and 50%. \n",
    "    # At every layer, we use “Dense” which means that the units are fully connected. \n",
    "    \n",
    "    # second hidden layer\n",
    "    #classifier.add(Dense(output_dim = 25, kernel_regularizer = regularizers.l2(0.01), activity_regularizer = regularizers.l1(0.01), init ='uniform', activation = 'relu', input_dim = 49))         \n",
    "    classifier.add(Dense(25, activation = 'relu', name=\"second_hidden_layer\"))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    #classifier.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "    # third hidden layer\n",
    "    classifier.add(Dense(25, activation = 'relu', name=\"third_hidden_layer\"))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    #classifier.add(Dropout(0.5))\n",
    "    \n",
    "    # 4th hidden layer\n",
    "    classifier.add(Dense(25, activation = 'relu', name=\"forth_hidden_layer\"))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    #classifier.add(Dropout(0.5))\n",
    "    \n",
    "    #classifier.add(Dense(output_dim = 2, activation = 'softmax', name=\"output_layer\"))\n",
    "    classifier.add(Dense(2, activation='softmax', name=\"final_layer\"))\n",
    "    return classifier\n",
    "\n",
    "classifier=get_sequential_dnn()\n",
    "classifier.summary()\n",
    "#print(len(classifier.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folds: 10\n",
      "\n",
      "Fold #1\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_metrics/metrics.py:51: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`inputs` is now automatically inferred\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_metrics/metrics.py:26: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.6987 - precision: 0.4167 - recall: 0.5113 - acc: 0.5160 - val_loss: 0.6926 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_acc: 0.5333\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6782 - precision: 0.4093 - recall: 0.1739 - acc: 0.5679 - val_loss: 0.6687 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_acc: 0.5333\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6675 - precision: 0.4679 - recall: 0.1951 - acc: 0.5901 - val_loss: 0.6348 - val_precision: 0.9167 - val_recall: 0.2676 - val_acc: 0.6444\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6445 - precision: 0.7541 - recall: 0.2022 - acc: 0.6296 - val_loss: 0.6012 - val_precision: 0.7650 - val_recall: 0.4271 - val_acc: 0.7556\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6112 - precision: 0.6536 - recall: 0.4706 - acc: 0.6741 - val_loss: 0.5843 - val_precision: 0.7541 - val_recall: 0.3762 - val_acc: 0.6667\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5978 - precision: 0.6549 - recall: 0.4692 - acc: 0.6988 - val_loss: 0.5306 - val_precision: 0.7058 - val_recall: 0.6253 - val_acc: 0.7556\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5639 - precision: 0.6753 - recall: 0.7084 - acc: 0.7136 - val_loss: 0.5505 - val_precision: 0.7633 - val_recall: 0.5911 - val_acc: 0.7333\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5906 - precision: 0.7269 - recall: 0.5299 - acc: 0.7086 - val_loss: 0.5315 - val_precision: 0.6335 - val_recall: 0.7767 - val_acc: 0.7111\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5514 - precision: 0.7361 - recall: 0.5891 - acc: 0.7160 - val_loss: 0.5110 - val_precision: 0.7871 - val_recall: 0.6076 - val_acc: 0.7778\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5398 - precision: 0.7349 - recall: 0.5792 - acc: 0.7383 - val_loss: 0.5031 - val_precision: 0.7313 - val_recall: 0.6076 - val_acc: 0.7556\n",
      "Test: [[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "1.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         14   4   18\n",
      "PA          7  20   27\n",
      "All        21  24   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         14   4   18\n",
      "PA          7  20   27\n",
      "All        21  24   45\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #2\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.5339 - precision: 0.7037 - recall: 0.6045 - acc: 0.7284 - val_loss: 0.5888 - val_precision: 0.6898 - val_recall: 0.9004 - val_acc: 0.7111\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5124 - precision: 0.7560 - recall: 0.6384 - acc: 0.7531 - val_loss: 0.5819 - val_precision: 0.4788 - val_recall: 0.4006 - val_acc: 0.6444\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4875 - precision: 0.7506 - recall: 0.6780 - acc: 0.7852 - val_loss: 0.6240 - val_precision: 0.6798 - val_recall: 0.5548 - val_acc: 0.6444\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4798 - precision: 0.8005 - recall: 0.6659 - acc: 0.8049 - val_loss: 0.6377 - val_precision: 0.6532 - val_recall: 0.9004 - val_acc: 0.6889\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4948 - precision: 0.7320 - recall: 0.7031 - acc: 0.7531 - val_loss: 0.5944 - val_precision: 0.4737 - val_recall: 0.4006 - val_acc: 0.6222\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4521 - precision: 0.7060 - recall: 0.6633 - acc: 0.7704 - val_loss: 0.5974 - val_precision: 0.6199 - val_recall: 0.5526 - val_acc: 0.6889\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4555 - precision: 0.7730 - recall: 0.6735 - acc: 0.7901 - val_loss: 0.6392 - val_precision: 0.5846 - val_recall: 0.9518 - val_acc: 0.6889\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4658 - precision: 0.7272 - recall: 0.7402 - acc: 0.7630 - val_loss: 0.6067 - val_precision: 0.6127 - val_recall: 0.8609 - val_acc: 0.6444\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4621 - precision: 0.7229 - recall: 0.7557 - acc: 0.7827 - val_loss: 0.5801 - val_precision: 0.6484 - val_recall: 0.8609 - val_acc: 0.6889\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4527 - precision: 0.8120 - recall: 0.7556 - acc: 0.7877 - val_loss: 0.5759 - val_precision: 0.6594 - val_recall: 0.9004 - val_acc: 0.7111\n",
      "Test: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "2.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         16  10   26\n",
      "PA          3  16   19\n",
      "All        19  26   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         30  14   44\n",
      "PA         10  36   46\n",
      "All        40  50   90\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #3\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4347 - precision: 0.8068 - recall: 0.7766 - acc: 0.8074 - val_loss: 0.5209 - val_precision: 0.6245 - val_recall: 0.3320 - val_acc: 0.7556\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4502 - precision: 0.7105 - recall: 0.6734 - acc: 0.7926 - val_loss: 0.4796 - val_precision: 0.7361 - val_recall: 0.3320 - val_acc: 0.7778\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4569 - precision: 0.7684 - recall: 0.7293 - acc: 0.7852 - val_loss: 0.4776 - val_precision: 0.7361 - val_recall: 0.3320 - val_acc: 0.7778\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4490 - precision: 0.7973 - recall: 0.7461 - acc: 0.8000 - val_loss: 0.5085 - val_precision: 0.6856 - val_recall: 0.3320 - val_acc: 0.7556\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4520 - precision: 0.7894 - recall: 0.7408 - acc: 0.7901 - val_loss: 0.4458 - val_precision: 0.6148 - val_recall: 0.4904 - val_acc: 0.7778\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4138 - precision: 0.7999 - recall: 0.7192 - acc: 0.7926 - val_loss: 0.4724 - val_precision: 0.7361 - val_recall: 0.3320 - val_acc: 0.7778\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4368 - precision: 0.8086 - recall: 0.7507 - acc: 0.7951 - val_loss: 0.4839 - val_precision: 0.7361 - val_recall: 0.3320 - val_acc: 0.7778\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4129 - precision: 0.8397 - recall: 0.7012 - acc: 0.8173 - val_loss: 0.5310 - val_precision: 0.7361 - val_recall: 0.3320 - val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4105 - precision: 0.8047 - recall: 0.7781 - acc: 0.8173 - val_loss: 0.4861 - val_precision: 0.5435 - val_recall: 0.3320 - val_acc: 0.7333\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4079 - precision: 0.8236 - recall: 0.7372 - acc: 0.8148 - val_loss: 0.5184 - val_precision: 0.7361 - val_recall: 0.3320 - val_acc: 0.7778\n",
      "Test: [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "3.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC          9   2   11\n",
      "PA          8  26   34\n",
      "All        17  28   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         39  16   55\n",
      "PA         18  62   80\n",
      "All        57  78  135\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #4\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.4389 - precision: 0.8254 - recall: 0.6991 - acc: 0.8074 - val_loss: 0.3834 - val_precision: 0.8517 - val_recall: 0.8163 - val_acc: 0.7778\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.4382 - precision: 0.7919 - recall: 0.6956 - acc: 0.8074 - val_loss: 0.3457 - val_precision: 0.9573 - val_recall: 0.9065 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3917 - precision: 0.7811 - recall: 0.7132 - acc: 0.8222 - val_loss: 0.3765 - val_precision: 0.8173 - val_recall: 0.9065 - val_acc: 0.8667\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4234 - precision: 0.7687 - recall: 0.6648 - acc: 0.8148 - val_loss: 0.3266 - val_precision: 0.9505 - val_recall: 0.8295 - val_acc: 0.8444\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3908 - precision: 0.8492 - recall: 0.7087 - acc: 0.8469 - val_loss: 0.3641 - val_precision: 0.7576 - val_recall: 0.6564 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4056 - precision: 0.7638 - recall: 0.8312 - acc: 0.8049 - val_loss: 0.3201 - val_precision: 0.8236 - val_recall: 0.8944 - val_acc: 0.8444\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3924 - precision: 0.8124 - recall: 0.7840 - acc: 0.8272 - val_loss: 0.3435 - val_precision: 0.9489 - val_recall: 0.7049 - val_acc: 0.8222\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3827 - precision: 0.8418 - recall: 0.7658 - acc: 0.8198 - val_loss: 0.3866 - val_precision: 0.8123 - val_recall: 0.5903 - val_acc: 0.7333\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4121 - precision: 0.8580 - recall: 0.7589 - acc: 0.8198 - val_loss: 0.4049 - val_precision: 1.0000 - val_recall: 0.5662 - val_acc: 0.7556\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3921 - precision: 0.8382 - recall: 0.7080 - acc: 0.8074 - val_loss: 0.3532 - val_precision: 0.9467 - val_recall: 0.6939 - val_acc: 0.8444\n",
      "Test: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "4.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         16   1   17\n",
      "PA          6  22   28\n",
      "All        22  23   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True       HC   PA  All\n",
      "Predicted              \n",
      "HC         55   17   72\n",
      "PA         24   84  108\n",
      "All        79  101  180\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #5\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3751 - precision: 0.8522 - recall: 0.8664 - acc: 0.8222 - val_loss: 0.4017 - val_precision: 0.6607 - val_recall: 0.8825 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3869 - precision: 0.7948 - recall: 0.8101 - acc: 0.8198 - val_loss: 0.4277 - val_precision: 0.6452 - val_recall: 0.8825 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3647 - precision: 0.7713 - recall: 0.8093 - acc: 0.8296 - val_loss: 0.3925 - val_precision: 0.6100 - val_recall: 0.7234 - val_acc: 0.8667\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3815 - precision: 0.7704 - recall: 0.7543 - acc: 0.8099 - val_loss: 0.4404 - val_precision: 0.6100 - val_recall: 0.7234 - val_acc: 0.8667\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3784 - precision: 0.8435 - recall: 0.8601 - acc: 0.8272 - val_loss: 0.4034 - val_precision: 0.6534 - val_recall: 0.7234 - val_acc: 0.8889\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3836 - precision: 0.8038 - recall: 0.6720 - acc: 0.8000 - val_loss: 0.4252 - val_precision: 0.6534 - val_recall: 0.7234 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4043 - precision: 0.8036 - recall: 0.7334 - acc: 0.8148 - val_loss: 0.4102 - val_precision: 0.7278 - val_recall: 0.4235 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3739 - precision: 0.8623 - recall: 0.7510 - acc: 0.8370 - val_loss: 0.4390 - val_precision: 0.5962 - val_recall: 0.6761 - val_acc: 0.8444\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3416 - precision: 0.8198 - recall: 0.7899 - acc: 0.8321 - val_loss: 0.5425 - val_precision: 0.6062 - val_recall: 0.7234 - val_acc: 0.8444\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3477 - precision: 0.8401 - recall: 0.8285 - acc: 0.8494 - val_loss: 0.4086 - val_precision: 0.7586 - val_recall: 0.4826 - val_acc: 0.8222\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f471846c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test: [[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "5.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC          7   2    9\n",
      "PA          6  30   36\n",
      "All        13  32   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True       HC   PA  All\n",
      "Predicted              \n",
      "HC         62   19   81\n",
      "PA         30  114  144\n",
      "All        92  133  225\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #6\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3916 - precision: 0.8144 - recall: 0.7067 - acc: 0.8321 - val_loss: 0.2151 - val_precision: 0.7643 - val_recall: 0.9320 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3629 - precision: 0.8117 - recall: 0.7807 - acc: 0.8568 - val_loss: 0.1789 - val_precision: 0.8070 - val_recall: 0.9320 - val_acc: 0.9556\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3753 - precision: 0.8578 - recall: 0.8569 - acc: 0.8444 - val_loss: 0.2063 - val_precision: 0.7393 - val_recall: 0.9320 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3853 - precision: 0.7842 - recall: 0.8259 - acc: 0.8296 - val_loss: 0.2427 - val_precision: 0.6770 - val_recall: 0.9320 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3712 - precision: 0.7994 - recall: 0.8146 - acc: 0.8321 - val_loss: 0.2153 - val_precision: 0.7029 - val_recall: 0.9320 - val_acc: 0.9111\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3658 - precision: 0.8193 - recall: 0.8405 - acc: 0.8321 - val_loss: 0.2370 - val_precision: 0.8017 - val_recall: 0.8807 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3640 - precision: 0.8325 - recall: 0.7857 - acc: 0.8395 - val_loss: 0.2242 - val_precision: 1.0000 - val_recall: 0.9320 - val_acc: 0.9778\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3920 - precision: 0.7371 - recall: 0.7619 - acc: 0.8222 - val_loss: 0.2325 - val_precision: 0.7643 - val_recall: 0.9320 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3828 - precision: 0.7283 - recall: 0.6974 - acc: 0.8148 - val_loss: 0.2116 - val_precision: 0.8070 - val_recall: 0.9320 - val_acc: 0.9556\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3606 - precision: 0.7898 - recall: 0.6394 - acc: 0.8123 - val_loss: 0.1817 - val_precision: 1.0000 - val_recall: 0.9320 - val_acc: 0.9778\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f47184a9ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test: [[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "6.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         23   0   23\n",
      "PA          1  21   22\n",
      "All        24  21   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True        HC   PA  All\n",
      "Predicted               \n",
      "HC          85   19  104\n",
      "PA          31  135  166\n",
      "All        116  154  270\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #7\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4020 - precision: 0.8359 - recall: 0.8295 - acc: 0.8321 - val_loss: 0.2829 - val_precision: 0.9008 - val_recall: 0.8394 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3259 - precision: 0.8722 - recall: 0.8064 - acc: 0.8543 - val_loss: 0.2909 - val_precision: 0.7726 - val_recall: 0.9677 - val_acc: 0.8889\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3491 - precision: 0.8363 - recall: 0.8613 - acc: 0.8444 - val_loss: 0.3824 - val_precision: 0.5673 - val_recall: 0.9677 - val_acc: 0.7778\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3451 - precision: 0.7841 - recall: 0.8492 - acc: 0.8321 - val_loss: 0.3197 - val_precision: 0.7513 - val_recall: 0.9353 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3386 - precision: 0.8250 - recall: 0.8530 - acc: 0.8494 - val_loss: 0.2909 - val_precision: 0.9064 - val_recall: 0.8717 - val_acc: 0.9111\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3356 - precision: 0.8727 - recall: 0.7946 - acc: 0.8469 - val_loss: 0.3021 - val_precision: 0.9008 - val_recall: 0.8394 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3253 - precision: 0.8589 - recall: 0.7204 - acc: 0.8247 - val_loss: 0.3040 - val_precision: 0.8801 - val_recall: 0.8394 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3356 - precision: 0.8306 - recall: 0.8209 - acc: 0.8444 - val_loss: 0.3128 - val_precision: 0.6500 - val_recall: 0.9677 - val_acc: 0.8444\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3610 - precision: 0.8086 - recall: 0.8182 - acc: 0.8247 - val_loss: 0.3331 - val_precision: 0.7513 - val_recall: 0.9353 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3424 - precision: 0.8110 - recall: 0.8389 - acc: 0.8519 - val_loss: 0.3061 - val_precision: 0.6449 - val_recall: 0.8717 - val_acc: 0.8222\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f47302db3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test: [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "\n",
      "7.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         14   6   20\n",
      "PA          2  23   25\n",
      "All        16  29   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True        HC   PA  All\n",
      "Predicted               \n",
      "HC          99   25  124\n",
      "PA          33  158  191\n",
      "All        132  183  315\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #8\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.3395 - precision: 0.8287 - recall: 0.8096 - acc: 0.8420 - val_loss: 0.2313 - val_precision: 0.9172 - val_recall: 0.8228 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3569 - precision: 0.8314 - recall: 0.8735 - acc: 0.8420 - val_loss: 0.2285 - val_precision: 0.9109 - val_recall: 0.7855 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3473 - precision: 0.8480 - recall: 0.8401 - acc: 0.8346 - val_loss: 0.2806 - val_precision: 0.9044 - val_recall: 0.7410 - val_acc: 0.8444\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3159 - precision: 0.8523 - recall: 0.8036 - acc: 0.8543 - val_loss: 0.2152 - val_precision: 0.7205 - val_recall: 0.8673 - val_acc: 0.8667\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3182 - precision: 0.8790 - recall: 0.8507 - acc: 0.8691 - val_loss: 0.2381 - val_precision: 0.7205 - val_recall: 0.8673 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3303 - precision: 0.8617 - recall: 0.8083 - acc: 0.8593 - val_loss: 0.1902 - val_precision: 0.9223 - val_recall: 0.8673 - val_acc: 0.9111\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3178 - precision: 0.8502 - recall: 0.8182 - acc: 0.8469 - val_loss: 0.2603 - val_precision: 0.8262 - val_recall: 0.8141 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3347 - precision: 0.8711 - recall: 0.8322 - acc: 0.8543 - val_loss: 0.2544 - val_precision: 0.7706 - val_recall: 0.8673 - val_acc: 0.8889\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3354 - precision: 0.8668 - recall: 0.7871 - acc: 0.8494 - val_loss: 0.2612 - val_precision: 0.9108 - val_recall: 0.7784 - val_acc: 0.8667\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3064 - precision: 0.8431 - recall: 0.8377 - acc: 0.8494 - val_loss: 0.2265 - val_precision: 0.7205 - val_recall: 0.8673 - val_acc: 0.8667\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f46f466f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test: [[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "8.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         16   3   19\n",
      "PA          3  23   26\n",
      "All        19  26   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True        HC   PA  All\n",
      "Predicted               \n",
      "HC         115   28  143\n",
      "PA          36  181  217\n",
      "All        151  209  360\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #9\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.4097 - precision: 0.8485 - recall: 0.8442 - acc: 0.8593 - val_loss: 0.2167 - val_precision: 0.9621 - val_recall: 0.9235 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3071 - precision: 0.9067 - recall: 0.8516 - acc: 0.8716 - val_loss: 0.2100 - val_precision: 0.9872 - val_recall: 0.9012 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3021 - precision: 0.8022 - recall: 0.8255 - acc: 0.8716 - val_loss: 0.1840 - val_precision: 0.9621 - val_recall: 0.9235 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3068 - precision: 0.8262 - recall: 0.8135 - acc: 0.8346 - val_loss: 0.2738 - val_precision: 1.0000 - val_recall: 0.9043 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3398 - precision: 0.7890 - recall: 0.7915 - acc: 0.8519 - val_loss: 0.1864 - val_precision: 1.0000 - val_recall: 0.9926 - val_acc: 0.9778\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2957 - precision: 0.8603 - recall: 0.8129 - acc: 0.8667 - val_loss: 0.2421 - val_precision: 1.0000 - val_recall: 0.6683 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3027 - precision: 0.8250 - recall: 0.7679 - acc: 0.8568 - val_loss: 0.2184 - val_precision: 1.0000 - val_recall: 0.7620 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3084 - precision: 0.8924 - recall: 0.8309 - acc: 0.8593 - val_loss: 0.2183 - val_precision: 0.9511 - val_recall: 0.9235 - val_acc: 0.9111\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3190 - precision: 0.8588 - recall: 0.8432 - acc: 0.8543 - val_loss: 0.2069 - val_precision: 0.8542 - val_recall: 0.9926 - val_acc: 0.9111\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2785 - precision: 0.8361 - recall: 0.7688 - acc: 0.8716 - val_loss: 0.2242 - val_precision: 0.8700 - val_recall: 1.0000 - val_acc: 0.9111\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f46f4422040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test: [[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "\n",
      "9.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         23   4   27\n",
      "PA          0  18   18\n",
      "All        23  22   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True        HC   PA  All\n",
      "Predicted               \n",
      "HC         138   32  170\n",
      "PA          36  199  235\n",
      "All        174  231  405\n",
      "\n",
      "__________________________________\n",
      "\n",
      "\n",
      "Fold #10\n",
      "\n",
      "Epoch 1/10\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.3234 - precision: 0.8355 - recall: 0.8258 - acc: 0.8395 - val_loss: 0.2054 - val_precision: 0.8559 - val_recall: 0.9657 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3147 - precision: 0.7964 - recall: 0.8891 - acc: 0.8568 - val_loss: 0.2434 - val_precision: 1.0000 - val_recall: 0.8615 - val_acc: 0.8889\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.2951 - precision: 0.8341 - recall: 0.8297 - acc: 0.8691 - val_loss: 0.2071 - val_precision: 0.9222 - val_recall: 0.8615 - val_acc: 0.8667\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.3081 - precision: 0.8574 - recall: 0.8104 - acc: 0.8716 - val_loss: 0.2084 - val_precision: 1.0000 - val_recall: 0.9505 - val_acc: 0.9556\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.2744 - precision: 0.8912 - recall: 0.8383 - acc: 0.8790 - val_loss: 0.2246 - val_precision: 0.9846 - val_recall: 0.9250 - val_acc: 0.9111\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3275 - precision: 0.8288 - recall: 0.7648 - acc: 0.8321 - val_loss: 0.2015 - val_precision: 0.8455 - val_recall: 0.9745 - val_acc: 0.9111\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.2934 - precision: 0.8283 - recall: 0.8363 - acc: 0.8667 - val_loss: 0.2797 - val_precision: 0.9145 - val_recall: 0.7115 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.2700 - precision: 0.8600 - recall: 0.8180 - acc: 0.8815 - val_loss: 0.3369 - val_precision: 1.0000 - val_recall: 0.6285 - val_acc: 0.8222\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.2849 - precision: 0.8521 - recall: 0.8290 - acc: 0.8815 - val_loss: 0.2168 - val_precision: 0.9198 - val_recall: 0.8379 - val_acc: 0.8667\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.3462 - precision: 0.8081 - recall: 0.7869 - acc: 0.8642 - val_loss: 0.2065 - val_precision: 0.8586 - val_recall: 0.9912 - val_acc: 0.9333\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f46f418c310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "10.fold's confusion matrix:\n",
      "\n",
      "True       HC  PA  All\n",
      "Predicted             \n",
      "HC         18   2   20\n",
      "PA          1  24   25\n",
      "All        19  26   45\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True        HC   PA  All\n",
      "Predicted               \n",
      "HC         156   34  190\n",
      "PA          37  223  260\n",
      "All        193  257  450\n",
      "\n",
      "__________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4 #  128\n",
    "EPOCHS = 10\n",
    "\n",
    "fold_number = 10\n",
    "kf = KFold(fold_number)\n",
    "fold = 0\n",
    "#cm_sum = np.empty([2,2])\n",
    "pred_list = []\n",
    "y_list = []\n",
    "notrounded_list = []\n",
    "print(\"Number of folds: {}\".format(fold_number))\n",
    "\n",
    "#kfold = StratifiedKFold(n_splits=fold_number shuffle=True, random_state=42)\n",
    "for train, test in kf.split(scaled_data):\n",
    "    \n",
    "    fold = fold + 1\n",
    "    print(\"\")\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "    print(\"\")\n",
    "    \n",
    "    x_train = scaled_data[train]\n",
    "    y_train = y_categorical[train]\n",
    "    x_test = scaled_data[test]\n",
    "    y_test = y_categorical[test]\n",
    "      \n",
    "    #classifier.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=[keras_metrics.precision(), keras_metrics.recall(), 'acc'])\n",
    "    #classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[keras_metrics.precision(), keras_metrics.recall(), 'acc'])\n",
    "    classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras_metrics.precision(), keras_metrics.recall(), 'acc'])\n",
    "        \n",
    "    # Fit the model    \n",
    "    #classifier.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=150, verbose=0) \n",
    "\n",
    "    classifier.fit(x_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data = (x_test, y_test))\n",
    "    \n",
    "\n",
    "    # Predicting test labels    \n",
    "    \n",
    "    pred = classifier.predict(x_test)\n",
    "    notrounded = pred\n",
    "    notrounded_list.extend(notrounded)\n",
    "    \n",
    "    \n",
    "    pred = pred.round().astype(int)\n",
    "    pred = pred.reshape(y_test.shape)\n",
    "    \n",
    "    #scores = classifier.evaluate(x_test, y_test)\n",
    "    \n",
    "    print('Test:', y_test)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    #cm = confusion_matrix(y_test, pred)\n",
    "    #cm_sum += cm\n",
    "    \n",
    "    #print(\"y_test\")\n",
    "    #print(y_test)\n",
    "    #print(\"pred\")\n",
    "    #print(pred)\n",
    "    \n",
    "    #print(\"cm:\")\n",
    "    #print(cm)\n",
    "    #print(\"\")\n",
    "    #print(\"cum_sum:\")\n",
    "    #print(cm_sum)\n",
    "    pred = pred.astype('str')\n",
    "    y_test = y_test.astype('str')\n",
    "    pred[pred == '0'] = decode[0]\n",
    "    pred[pred == '1'] = decode[1]\n",
    "    y_test[y_test == '0'] = decode[0]\n",
    "    y_test[y_test == '1'] = decode[1]\n",
    "    \n",
    "    pred_list.extend(pred)\n",
    "    y_list.extend(y_test)\n",
    "\n",
    "    y_actu = pd.Series(y_test, name='True')\n",
    "    y_pred = pd.Series(pred, name='Pred')\n",
    "    df_confusion = pd.crosstab(y_pred, y_actu, colnames=['True'], rownames=['Predicted'], margins=True)\n",
    "    print(\"\")\n",
    "    print(\"{}.fold's confusion matrix:\".format(fold))\n",
    "    print(\"\")\n",
    "    print(df_confusion)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"The classifier's confusion matrix\")\n",
    "    print(\"\")\n",
    "    y_actu = pd.Series(y_list, name='True')\n",
    "    y_pred = pd.Series(pred_list, name='Pred')\n",
    "    df_finalconf = pd.crosstab(y_pred, y_actu, colnames=['True'], rownames=['Predicted'], margins=True)\n",
    "    print(df_finalconf)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"__________________________________\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__________________________________\n",
      "\n",
      "The classifier's confusion matrix\n",
      "\n",
      "True        HC   PA  All\n",
      "Predicted               \n",
      "HC         156   34  190\n",
      "PA          37  223  260\n",
      "All        193  257  450\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"__________________________________\")\n",
    "print(\"\")\n",
    "print(\"The classifier's confusion matrix\")\n",
    "print(\"\")\n",
    "y_actu = pd.Series(y_list, name='True')\n",
    "y_pred = pd.Series(pred_list, name='Pred')\n",
    "df_finalconf = pd.crosstab(y_pred, y_actu, colnames=['True'], rownames=['Predicted'], margins=True)\n",
    "print(df_finalconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156  34]\n",
      " [ 37 223]]\n"
     ]
    }
   ],
   "source": [
    "cm_final = df_finalconf.iloc[0:-1].values\n",
    "\n",
    "cm_final = cm_final[:,[0,1]]\n",
    "print(cm_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Statistical measures calculated from Confusion Matrix #\n",
    "#########################################################\n",
    "import math\n",
    "\n",
    "# (tp + tn) / (tp + fp + tn + fn)\n",
    "def get_accuracy(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    #print([tp, fp], [fn, tn])\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "# sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "# tp / (tp + fn)\n",
    "def get_recall(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "# precision or positive predictive value (PPV)\n",
    "# tp / (tp + fp)\n",
    "def get_precision(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "# harmonic mean of precision and sensitivity\n",
    "# 2*((precision*recall)/(precision+recall))\n",
    "def get_f1score(mx):\n",
    "    return 2*((get_precision(mx)*get_recall(mx))/(get_precision(mx)+get_recall(mx)))\n",
    "\n",
    "# specificity, selectivity or true negative rate (TNR)\n",
    "# \n",
    "def get_specificity(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def get_sensitivity(mx):\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "def get_MCC(mx):\n",
    "    # Matthews Correlation Coefficient (MCC)\n",
    "    [tp, fp], [fn, tn] = mx\n",
    "    \n",
    "    return (tp*tn-fp*fn)/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________\n",
      "\n",
      "Accuracy: 0.842222\n",
      "Matthews Correlation Coefficient: 0.677368\n",
      "\n",
      "For class HC: \n",
      "\n",
      "Recall: 0.808290\n",
      "Precision: 0.821053\n",
      "F1 score: 0.814621\n",
      "Specificity: 0.808290\n",
      "Sensitivity: 0.867704\n",
      "\n",
      "For class PA: \n",
      "\n",
      "Recall: 0.867704\n",
      "Precision: 0.857692\n",
      "F1 score: 0.862669\n",
      "Specificity: 0.867704\n",
      "Sensitivity: 0.808290\n"
     ]
    }
   ],
   "source": [
    "# Calculating statistical measures from Confusion Matrix\n",
    "mx = cm_final\n",
    "print(\"__________________________________\")\n",
    "print(\"\")\n",
    "print('Accuracy: %f' % get_accuracy(mx))\n",
    "print('Matthews Correlation Coefficient: %f' % get_MCC(mx))\n",
    "print(\"\")\n",
    "\n",
    "print(\"For class {}: \".format(df_finalconf.columns[0]) )\n",
    "print(\"\")\n",
    "print('Recall: %f' % get_recall(mx))\n",
    "print('Precision: %f' % get_precision(mx))\n",
    "print('F1 score: %f' % get_f1score(mx))\n",
    "print('Specificity: %f' % get_specificity(mx))\n",
    "print('Sensitivity: %f' % get_sensitivity(mx))\n",
    "\n",
    "[tn, fp], [fn, tp] = mx\n",
    "mx_ = [tp, fn],[fp, tn]\n",
    "print(\"\")\n",
    "print(\"For class {}: \".format(df_finalconf.columns[1]) )\n",
    "print(\"\")\n",
    "print('Recall: %f' % get_recall(mx_))\n",
    "print('Precision: %f' % get_precision(mx_))\n",
    "print('F1 score: %f' % get_f1score(mx_))\n",
    "print('Specificity: %f' % get_specificity(mx_))\n",
    "print('Sensitivity: %f' % get_sensitivity(mx_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
